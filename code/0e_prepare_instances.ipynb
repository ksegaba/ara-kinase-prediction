{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the instance files for model building\n",
    "**Conda env:** /home/seguraab/miniconda3/envs/py310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 20250403_melissa_ara_data\n",
    "For classification models:\n",
    "1. Binary label for each trait: neg & pos GI as 1, no GI as 0 [sample from bins for the no GI]\n",
    "2. Binary label (all traits included): 1 if GI in at least one trait; 0 if no GI in any trait\n",
    "\n",
    "\n",
    "[Don't do for now] 3. Multiclass label for each trait: neg GI, pos GI, no GI [sample from bins]\n",
    "\n",
    "\n",
    "[Don't do for now] 4. Multiclass label (all traits included): all neg GI for any trait, all pos GI for any trait, no GI in any trait. [What to do if a GI is neg, but pos for a different trait? Perhaps only combine the \\<label\\>_\\<transformations\\> columns per label]\n",
    "\n",
    "[Don't do for now] Brianna suggested instead of multiclass, to create binary labels (0/1 for neg GI; 0/1 for pos GI; 0/1 for not-detected), these could be used in a multi-output classification. Instead of multiclass classification.\n",
    "\n",
    "5. Relax the p-value to 0.1 and re-create the above 4 labels\n",
    "\n",
    "For regression models:\n",
    "1. \n",
    "\n",
    "I'll combine all of these labels into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in epistasis data\n",
    "import os\n",
    "import pandas as pd\n",
    "dir_path = '/home/seguraab/ara-kinase-prediction/data/20250403_melissa_ara_data/corrected_data'\n",
    "data_linear = pd.read_csv(f'{dir_path}/fitness_data_04032025_epistasis_linear_with_no_int.csv') # from linear model\n",
    "data_mani = [f for f in os.listdir(dir_path) if f.endswith('emmeans_epistasis.tsv')] # Mani 2008 definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample_neg_set_bins(neg_set, num_bins=10, num_samples=50):\n",
    "    '''Sample equally from the negative set distribution using bins'''\n",
    "    neg_set = neg_set.copy(deep=True)\n",
    "    \n",
    "    # Create bins\n",
    "    neg_set_bins = np.linspace(neg_set.e_est.min(), neg_set.e_est.max(), num_bins + 1)\n",
    "    neg_set['bins'] = pd.cut(neg_set.e_est, bins=neg_set_bins, include_lowest=True)\n",
    "    \n",
    "    # Sample equally from each bin\n",
    "    num_samp_per_bin = num_samples // num_bins\n",
    "    sampled_data = neg_set.groupby('bins').apply(\n",
    "        lambda x: x.sample(n=min(len(x), num_samp_per_bin), random_state=2305))\n",
    "    sampled_data = sampled_data.reset_index(drop=True)\n",
    "    \n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "def make_imbalanced_binary_labels_from_linear_model(data_linear):\n",
    "    '''Generate imbalanced binary labels using epistasis estimates from the\n",
    "    linear model'''\n",
    "    \n",
    "    # Store labels in a dictionary\n",
    "    labels = {}\n",
    "    \n",
    "    for cutoff, pval in zip([0.05, 0.1], ['p05', 'p1']):\n",
    "        # Subset the data by p-value cutoffs\n",
    "        neg_set = data_linear[data_linear.pval_e >= cutoff]\n",
    "        pos_set = data_linear[data_linear.pval_e < cutoff]\n",
    "        # pos_set_size = pos_set.groupby('Label').count() # size of positive set, to balance negative set\n",
    "        \n",
    "        # Binary label for each trait------------------------------------------#\n",
    "        for label in pos_set['Label'].unique():\n",
    "            # positive set for this label\n",
    "            label_pos_set = pos_set[pos_set['Label'] == label].copy(deep=True)\n",
    "            label_pos_set['ML_label'] = 1\n",
    "            \n",
    "            '''Don't need this since the RF & XGB code does this already:\n",
    "            # balanced negative set label\n",
    "            balanced_neg_set = sample_neg_set_bins(neg_set[neg_set['Label'] == label],\n",
    "                num_samples=pos_set_size.loc[label, 'Set'])\n",
    "            balanced_neg_set['ML_label'] = 0\n",
    "            '''\n",
    "            \n",
    "            # negative set for this label\n",
    "            label_neg_set = neg_set[neg_set['Label'] == label].copy(deep=True)\n",
    "            label_neg_set['ML_label'] = 0\n",
    "            \n",
    "            # ensure set numbers don't overlap\n",
    "            assert label_pos_set.Set.isin(label_neg_set.Set).sum() == 0, \\\n",
    "                f'Overlapping sets for {label} in {pval}'\n",
    "            \n",
    "            # combine the positive and negative sets and assign name to the label\n",
    "            labels[f'binary_{label}_{pval}'] = pd.concat([\n",
    "                label_neg_set.set_index('Set')['ML_label'],\n",
    "                label_pos_set.set_index('Set')['ML_label']], axis=0)\n",
    "            del label_pos_set, label_neg_set\n",
    "        \n",
    "        # Imbalanced binary label for all traits combined---------------------------------#\n",
    "        # note: not all sets fell under the p-value cutoff for all the traits,\n",
    "        # but since the genes are interacting, then I am setting the label to 1.\n",
    "        # The code below could be simpler, but I wanted to make it this point clear.\n",
    "        pos_set['ML_label'] = 1\n",
    "        pos_set = pos_set.pivot(index='Set', columns='Label', values='ML_label').any(axis=1) # will have NaN because of the note above\n",
    "        \n",
    "        # set all positive set instances to 1 if they are not all 1\n",
    "        if pos_set.value_counts().get(True)!=len(pos_set):\n",
    "            pos_set = pd.Series(1, index=pos_set[pos_set].index)\n",
    "        \n",
    "        # negative set\n",
    "        neg_set = data_linear[~data_linear.Set.isin(pos_set.index)].copy(deep=True)\n",
    "        neg_set['ML_label'] = 0\n",
    "        neg_set = neg_set.pivot(index='Set', columns='Label', values='ML_label').any(axis=1).astype(int)\n",
    "        \n",
    "        # combine the positive and negative sets and assign name to the label\n",
    "        labels[f'binary_combined_{pval}'] = pd.concat([neg_set, pos_set], axis=0)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def make_imbalanced_multiclass_labels_from_linear_model(data_linear):\n",
    "    # Store labels in a dictionary\n",
    "    labels = {}\n",
    "    \n",
    "    for cutoff, pval in zip([0.05, 0.1], ['p05', 'p1']):\n",
    "        # Subset the data by p-value cutoffs\n",
    "        neg_set = data_linear[data_linear.pval_e >= cutoff] # not_detected\n",
    "        pos_set = data_linear[data_linear.pval_e < cutoff] # positive & negative GIs\n",
    "        \n",
    "        # Binary label for each trait------------------------------------------#\n",
    "        for label in pos_set['Label'].unique():\n",
    "            # significant positive and negative GIs classes for this label\n",
    "            label_pos_set = pos_set[pos_set['Label'] == label].copy(deep=True)\n",
    "            label_pos_set['ML_label'] = label_pos_set['Epistasis_Direction'].str.lower()\n",
    "            \n",
    "            assert label_pos_set['ML_label'].nunique() == 2, \\\n",
    "                f'Label {label} has more than 2 unique values in Epistasis_Direction for the positive set'\n",
    "            \n",
    "            # insignificant gene pairs (no GI) class for this label\n",
    "            label_neg_set = neg_set[neg_set['Label'] == label].copy(deep=True)\n",
    "            label_neg_set['ML_label'] = label_neg_set['Epistasis_Direction'].str.lower()\n",
    "            label_neg_set['ML_label'] = label_neg_set['ML_label'].str.replace(' ', '_')\n",
    "            \n",
    "            assert label_neg_set['ML_label'].nunique() == 1, \\\n",
    "                f'Label {label} has more than 1 unique value in Epistasis_Direction for the negative set'\n",
    "                \n",
    "            # ensure set numbers don't overlap\n",
    "            assert label_pos_set.Set.isin(label_neg_set.Set).sum() == 0, f'Overlapping sets for {label} in {pval}'\n",
    "            \n",
    "            # combine the positive and negative sets and assign name to the label\n",
    "            labels[f'multiclass_{label}_{pval}'] = pd.concat([\n",
    "                label_neg_set.set_index('Set')['ML_label'],\n",
    "                label_pos_set.set_index('Set')['ML_label']], axis=0)\n",
    "            del label_pos_set, label_neg_set\n",
    "        \n",
    "        # Imbalanced binary label for all traits combined---------------------------------#\n",
    "        # note: not all sets fell under the p-value cutoff for all the traits,\n",
    "        # but since the genes are interacting, then I am setting the label to 1.\n",
    "        # The code below could be simpler, but I wanted to make it this point clear.\n",
    "        pos_set = pos_set.pivot(index='Set', columns='Label', values='Epistasis_Direction') # will have NaN because of the note above\n",
    "    \n",
    "        # set all positive set instances to 1 if they are not all 1\n",
    "        if pos_set.value_counts().get(True)!=len(pos_set):\n",
    "            pos_set = pd.Series(1, index=pos_set[pos_set].index)\n",
    "        \n",
    "        # negative set\n",
    "        neg_set = data_linear[~data_linear.Set.isin(pos_set.index)].copy(deep=True)\n",
    "        neg_set['ML_label'] = 0\n",
    "        neg_set = neg_set.pivot(index='Set', columns='Label', values='ML_label').any(axis=1).astype(int)\n",
    "        \n",
    "        # combine the positive and negative sets and assign name to the label\n",
    "        labels[f'binary_combined_{pval}'] = pd.concat([neg_set, pos_set], axis=0)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_757464/1136230926.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_set['ML_label'] = 1\n",
      "/tmp/ipykernel_757464/1136230926.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_set['ML_label'] = 1\n"
     ]
    }
   ],
   "source": [
    "# Note: there are sets with NaN values, that is because they were missing genotypes,\n",
    "# thus a linear model could not be fit. These sets will need to be removed within the\n",
    "# model training code.\n",
    "binary_labels = pd.DataFrame(make_imbalanced_binary_labels_from_linear_model(data_linear))\n",
    "\n",
    "# Insert gene names\n",
    "gene_names = pd.read_excel('/home/seguraab/ara-kinase-prediction/data/20240917_melissa_ara_data/fitness_data_for_Kenia_09172024.xlsx', sheet_name='gene_names')\n",
    "gene_names['Line'] = gene_names.Line.astype(str)\n",
    "gene_names = gene_names[['Line', 'MA', 'MB']].set_index('Line').to_dict()\n",
    "binary_labels.insert(0, 'gene1', binary_labels.index.map(gene_names['MA']).str.upper().str.strip())\n",
    "binary_labels.insert(1, 'gene2', binary_labels.index.map(gene_names['MB']).str.upper().str.strip())\n",
    "# binary_labels.loc[~binary_labels.index.isin(gene_names['MA'].keys())] # Will drop sets 77, 793, 813, 825, and 86\n",
    "binary_labels.dropna(subset=['gene1', 'gene2'], inplace=True)\n",
    "\n",
    "# Save to file\n",
    "binary_labels.to_csv(f'{dir_path}/binary_labels_from_linear_model.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 20240725_melissa_ara_data/interactions_fitness.txt\n",
    "For classification models:  \n",
    "1. Train/Val/Test: Melissa's alpha whole genome duplication gene pairs as instances. The label is 0 for no interaction and 1 for interaction.  \n",
    "2. Predict: Cusack 2021 kinase family gene pairs\n",
    "3. Predict: Kinase gene pairs from Araport11 (Won't do this)\n",
    "4. Predict: Kinase gene pairs from TAIR10\n",
    "\n",
    "For regression models:  \n",
    "1. Train/Val/Test: Melissa's gene pairs with the corrected total seed count (TSC) as the label\n",
    "2. Predict: All possible kinase family gene pairs\n",
    "3. Predict: Kinase gene pairs from Araport11 (Won't do this)\n",
    "4. Predict: Kinase gene pairs from TAIR10\n",
    "\n",
    "Additional instance files:  \n",
    "- All possible gene pair combinations as instances from the A. thaliana TAIR10 genome  \n",
    "- Single genes as instances from TAIR10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare instance file no. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10265, 2)\n",
      "(10250, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT3G46420</td>\n",
       "      <td>AT4G20450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT5G01820</td>\n",
       "      <td>AT5G57630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT2G37050</td>\n",
       "      <td>AT5G59660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT3G17840</td>\n",
       "      <td>AT3G51740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G11410</td>\n",
       "      <td>AT4G23190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>AT1G23380</td>\n",
       "      <td>AT1G70510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>AT1G26790</td>\n",
       "      <td>AT1G69570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10261</th>\n",
       "      <td>AT1G16060</td>\n",
       "      <td>AT1G79700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>AT1G21410</td>\n",
       "      <td>AT1G77000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>AT1G51880</td>\n",
       "      <td>AT3G21340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene1      gene2\n",
       "0      AT3G46420  AT4G20450\n",
       "1      AT5G01820  AT5G57630\n",
       "2      AT2G37050  AT5G59660\n",
       "3      AT3G17840  AT3G51740\n",
       "4      AT1G11410  AT4G23190\n",
       "...          ...        ...\n",
       "10259  AT1G23380  AT1G70510\n",
       "10260  AT1G26790  AT1G69570\n",
       "10261  AT1G16060  AT1G79700\n",
       "10262  AT1G21410  AT1G77000\n",
       "10264  AT1G51880  AT3G21340\n",
       "\n",
       "[10250 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the gene pairs from the two datasets\n",
    "ara_m = pd.read_csv('../data/20240725_melissa_ara_data/interactions_fitness.txt', sep='\\t') # Melissa's gene pairs\n",
    "ara_m.rename(columns={'MA': 'gene1', 'MB': 'gene2'}, inplace=True)\n",
    "kinases = pd.read_csv('../data/2021_cusack_data/Dataset_4.txt', sep='\\t')\n",
    "kinases = kinases.loc[kinases.Class=='test'] # these are the kinase family gene pairs\n",
    "\n",
    "# Split the gene pair identifier into two columns\n",
    "instances = kinases.pair_ID.str.split('_', expand=True)\n",
    "instances.columns = ['gene1', 'gene2']\n",
    "\n",
    "# Merge the instances\n",
    "instances = pd.concat([instances, ara_m[['gene1', 'gene2']]], axis=0, ignore_index=True)\n",
    "instances['gene1'] = instances['gene1'].str.upper()\n",
    "instances['gene2'] = instances['gene2'].str.upper()\n",
    "print(instances.shape) # (10265, 2)\n",
    "\n",
    "# Check for duplicate gene pairs\n",
    "instances = instances.apply(lambda x: sorted(x), axis=1) # sort the gene pairs\n",
    "instances = pd.DataFrame(instances.to_list(), columns=['gene1', 'gene2'])\n",
    "instances.drop_duplicates(inplace=True)\n",
    "print(instances.shape) # (10250, 2); 15 gene pairs overlapped with ara_m\n",
    "\n",
    "# Save the instances\n",
    "# instances.to_csv('../data/instances_dataset_1.txt', sep='\\t', index=False)\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/seguraab/ara-kinase-prediction')\n",
    "kinases = pd.read_csv('data/2021_cusack_data/Dataset_4.txt', sep='\\t')\n",
    "\n",
    "# sort instance identifiers\n",
    "sorted_IDs = kinases['pair_ID'].str.split('_').apply(sorted).str.join('_')\n",
    "sum(sorted_IDs == kinases.pair_ID.values) # they're exactly the same, good!\n",
    "\n",
    "# Note: I am going to generate features for Dataset_4.txt (saved to ara-kinase-prediction/data/2021_cusack_data/Dataset_4_Features/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create test set files\n",
    "These test sets will be used to evaluate model performance in a \"round robin\" style.\n",
    "For the cross-validation during model training, I will use:\n",
    "1. Leave-One-Out cross-validation with the remaining 9 folds\n",
    "2. Normal 9-fold cross-validation, excluding the test set for each round robin iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate instance from ara_m before assigning instances to CV folds\n",
    "ara_m = pd.read_csv('../data/20240725_melissa_ara_data/interactions_fitness.txt', sep='\\t') # Melissa's gene pairs\n",
    "ara_m.index = np.sort(ara_m[['MA', 'MB']], axis=1) # sort the gene pairs\n",
    "ara_m.index = ara_m.index.map(tuple) # convert to tuples\n",
    "ara_m.index[ara_m.index.duplicated()] # At1g18620 At1g74160 is duplicated (set 703)\n",
    "ara_m_no_dups = ara_m.loc[ara_m.index.drop_duplicates()] \n",
    "\n",
    "\n",
    "# Convert instances to uppercase\n",
    "ara_m_no_dups.index = ara_m_no_dups.index.set_levels(ara_m_no_dups.index.levels[0].map(str.upper), level=0)\n",
    "ara_m_no_dups.index = ara_m_no_dups.index.set_levels(ara_m_no_dups.index.levels[1].map(str.upper), level=1)\n",
    "ara_m_no_dups = ara_m_no_dups.loc[ara_m_no_dups.Set != 703]\n",
    "\n",
    "# Assign instances to CV folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=20240909)\n",
    "for i, (train_idx, test_idx) in enumerate(folds.split(ara_m_no_dups, ara_m_no_dups['Interaction'])):\n",
    "\tfold_i = ara_m_no_dups.loc[ara_m_no_dups.index[test_idx]].index.to_frame(index=False)\n",
    "\t\n",
    "\twith open(f'../data/test_sets_clf/test_ara_m_fold_{i}.txt', 'w') as out:\n",
    "\t\tfor j in range(fold_i.shape[0]):\n",
    "\t\t\tout.write(f'{fold_i.iloc[j,0]}_{fold_i.iloc[j,1]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare instance file of TAIR10 Kinase genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "\n",
    "# Kinase genes from NCBI\n",
    "genes = pd.read_csv(\"../data/Kinase_genes/kinase-athaliana-ncbi.tsv\", sep=\"\\t\")\n",
    "k_id = genes.apply(lambda x: x[\"Aliases\"].split(\",\")[0].strip() if isinstance(x[\"Aliases\"], str) else x, axis=1)\n",
    "print(k_id.apply(type).unique()) # type: ignore\n",
    "genes.iloc[k_id.loc[k_id.apply(lambda x: isinstance(x, pd.core.series.Series))].index,:][\"Aliases\"]\n",
    "\n",
    "k_id = k_id.loc[k_id.apply(lambda x: isinstance(x, str))].unique() # kinase genes (2235)\n",
    "\n",
    "# TAIR10 GFF genes\n",
    "gff = dt.fread(\"../data/TAIR10/Athaliana_167_gene.gff3\", skip_to_line=4).to_pandas()\n",
    "at_id = gff.loc[gff[\"C2\"]==\"gene\"].\\\n",
    "    apply(lambda x: x[\"C8\"].replace(\"ID=\", \"\").split(\";\")[0].strip() if isinstance(x[\"C8\"], str) else x, axis=1)\n",
    "\n",
    "# TAIR10 Kinase genes; generate all possible pairs\n",
    "tair10_kinases = np.intersect1d(k_id, at_id) # 2182 kinase genes\n",
    "pairs = list(itertools.combinations(tair10_kinases, 2)) # 2379471 pairs\n",
    "\n",
    "# Save the pairs to a file\n",
    "pd.DataFrame(pairs, columns=[\"gene1\", \"gene2\"]).to_csv(\n",
    "    \"../data/Kinase_genes/instances_tair10_kinases.txt\", index=False, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare instance file of Araport11 Kinase genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kinase genes from NCBI\n",
    "genes = pd.read_csv(\"../data/Kinase_genes/kinase-athaliana-ncbi.tsv\", sep=\"\\t\")\n",
    "k_id = genes.apply(lambda x: x[\"Aliases\"].split(\",\")[0].strip() if isinstance(x[\"Aliases\"], str) else x, axis=1)\n",
    "\n",
    "print(k_id.apply(type).unique()) # type: ignore\n",
    "# [<class 'str'> <class 'pandas.core.series.Series'>]\n",
    "genes.iloc[k_id.loc[k_id.apply(lambda x: isinstance(x, pd.core.series.Series))].index,:][\"Aliases\"] # these Aliases are NaN values\n",
    "\n",
    "k_id = k_id.loc[k_id.apply(lambda x: isinstance(x,str))].unique() # kinase genes (2235)\n",
    "\n",
    "# Araport11 GFF genes\n",
    "gff = dt.fread(\"../data/Araport11/Athaliana_447_Araport11.gene.gff3\", skip_to_line=4).to_pandas()\n",
    "at_id = gff.loc[gff[\"C2\"]==\"gene\"].\\\n",
    "    apply(lambda x: x[\"C8\"].replace(\"ID=\", \"\").split(\".\")[0].strip() if isinstance(x[\"C8\"], str) else x, axis=1)\n",
    "\n",
    "# Araport11 Kinase genes; generate all possible pairs\n",
    "araport11_kinases = np.intersect1d(k_id, at_id) # 2202 kinase genes\n",
    "pairs = list(itertools.combinations(araport11_kinases, 2)) # 2423301 pairs\n",
    "\n",
    "# Save the pairs to a file\n",
    "pd.DataFrame(pairs, columns=[\"gene1\", \"gene2\"]).to_csv(\n",
    "    \"../data/Kinase_genes/instances_araport11_kinases.txt\", index=False, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare instance file for single genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27416\n"
     ]
    }
   ],
   "source": [
    "import gffutils\n",
    "\n",
    "gff = '../data/TAIR10/Athaliana_167_TAIR10.gene.gff3'\n",
    "\n",
    "# Create the database\n",
    "db = gffutils.create_db(gff, dbfn='TAIR10.db', force=True, keep_order=True,\n",
    "                        merge_strategy='merge', sort_attribute_values=True) \n",
    "\n",
    "# Extract the gene information\n",
    "db = gffutils.FeatureDB('../data/TAIR10/TAIR10.db') # access the database\n",
    "genes = []\n",
    "for gene in db.features_of_type('gene'):\n",
    "    genes.append(gene['Name'][0])\n",
    "\n",
    "print(len(genes)) # 27416\n",
    "\n",
    "# Write the gene IDs to a file\n",
    "# with open('../data/instances_dataset_singles.txt', 'w') as f:\n",
    "#     f.write('gene\\n')\n",
    "#     for gene in genes:\n",
    "#         f.write('%s\\n' % gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare instance file no. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375804820"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Generate all possible gene pairs without duplicates\n",
    "gene_pairs = list(combinations(genes, 2))\n",
    "len(gene_pairs) # 375804820\n",
    "\n",
    "# Write the gene pairs to a file\n",
    "# with open('../data/instances_dataset_pairs.txt', 'w') as f:\n",
    "#     f.write('gene1\\tgene2\\n')\n",
    "#     for gene_pair in gene_pairs:\n",
    "#         f.write('%s\\t%s\\n' % gene_pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
