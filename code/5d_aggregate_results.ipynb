{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autogluon results for models built with 2259 imputed features, from which 15 balanced training datasets were obtained, and models were evaluated on 10 imbalanced test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_path = '/home/seguraab/ara-kinase-prediction/output_clf/ara_m_autogluon_2259_imp_feats'\n",
    "res = []\n",
    "imp = {}\n",
    "for i in range(10): # test sets\n",
    "    for j in range(15): # balanced training sets\n",
    "        dirp = f'{output_path}/ara_m_autogluon_test_{i}_balanced_{j}'\n",
    "        i_j_res = pd.read_csv(f'{dirp}/ara_m_autogluon_test_{i}_balanced_{j}_RESULTS.csv', index_col=0)\n",
    "        i_j_res.insert(0, 'Tag', f'ara_m_autogluon_test_{i}_balanced_{j}')\n",
    "        res.append(i_j_res)\n",
    "        \n",
    "        i_j_imp = pd.read_csv(f'{dirp}/ara_m_autogluon_test_{i}_balanced_{j}_IMPORTANCE.csv', index_col=0)\n",
    "        imp[f'ara_m_autogluon_test_{i}_balanced_{j}'] = i_j_imp\n",
    "        del i_j_res, i_j_imp\n",
    "        \n",
    "res = pd.concat(res, axis=0)\n",
    "# res.to_csv(f'{output_path}/ara_m_autogluon_2259_imp_feats_balanced_RESULTS.csv', index=False)\n",
    "\n",
    "imp = pd.concat(imp, axis=1)\n",
    "new_cols = [f'{level0}_{level1}' for level0, level1 in \\\n",
    "    zip(imp.columns.get_level_values(0), imp.columns.get_level_values(1))]\n",
    "imp.columns = new_cols\n",
    "# imp.to_csv(f'{output_path}/ara_m_autogluon_2259_imp_feats_balanced_IMPORTANCE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection results for XGBoost models built using the 2259 imputed features, 15 balanced training sets, and 10 imbalanced test sets. Feature selection was performed with RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "\n",
    "# Get the best feature selection run per test set and balanced dataset\n",
    "clf_res = dt.fread('/home/seguraab/ara-kinase-prediction/output_clf/ara_m_kfold_ht_2259_imp_feats_fs/RESULTS_xgboost.tsv').to_pandas()\n",
    "clf_res.insert(0, 'TestSet', clf_res.Tag.str.split('_').str[8])\n",
    "clf_res.insert(0, 'BalancedTrainSet', clf_res.Tag.str.split('_').str[10])\n",
    "best_runs = clf_res.groupby(['TestSet', 'BalancedTrainSet']).apply(lambda x: x['F1_val'].idxmax())\n",
    "clf_res_best = clf_res.iloc[best_runs]\n",
    "clf_res_best.to_csv('/home/seguraab/ara-kinase-prediction/output_clf/ara_m_kfold_ht_2259_imp_feats_fs/RESULTS_xgboost_best.csv', index=False)\n",
    "# note on clf_res_best: the best run F1 test is really bad even though F1_val looks good.\n",
    "\n",
    "# Get the average performance across different feature subsets per test set and balanced dataset\n",
    "clf_res['TestSet'] = clf_res['TestSet'].astype(int)\n",
    "clf_res['BalancedTrainSet'] = clf_res['BalancedTrainSet'].astype(int)\n",
    "clf_res_avg = clf_res.select_dtypes(np.number).groupby(['TestSet', 'BalancedTrainSet']).mean()\n",
    "clf_res_avg.to_csv('/home/seguraab/ara-kinase-prediction/output_clf/ara_m_kfold_ht_2259_imp_feats_fs/RESULTS_xgboost_avg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection curves\n",
    "None of the models have a test set performance above 0.5 with a reasonable validation F1.\n",
    "```python\n",
    ">>> clf_res.loc[clf_res.F1_test > 0.5, 'F1_val']\n",
    "# 387    0.330136\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the F1 score\n",
    "for test_set in range(10):\n",
    "    fig, ax = plt.subplots(5, 3, figsize=(8.5, 14.17), sharex=True, sharey=True) # to make the plots square\n",
    "    for i in range(5):\n",
    "        for j in range(3):\n",
    "            balanced_train_set = i * 3 + j\n",
    "            clf_res_subset = clf_res[(clf_res['TestSet'] == test_set) &\\\n",
    "                (clf_res['BalancedTrainSet'] == balanced_train_set)]\n",
    "            clf_res_subset = clf_res_subset.sort_values('NumFeatures')\n",
    "            ax[i, j].plot(clf_res_subset['NumFeatures'], clf_res_subset['F1_val'],\n",
    "                          label='F1_val', color='red')\n",
    "            ax[i, j].plot(clf_res_subset['NumFeatures'], clf_res_subset['F1_test'],\n",
    "                          label='F1_test', color='blue')\n",
    "            ax[i, j].set_title(f'Balanced Train Set {balanced_train_set}')\n",
    "            ax[i, j].set_xlabel('Number of Features')\n",
    "            ax[i, j].set_ylabel('F1 score')\n",
    "            ax[i, j].legend()\n",
    "    \n",
    "    fig.suptitle(f'Test Set {test_set}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/home/seguraab/ara-kinase-prediction/output_clf/ara_m_kfold_ht_2259_imp_feats_fs/0_figure_test_{test_set}_feature_selection.pdf')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
